---
title: "Ridge"
output: html_document
---

```{r}
library(ISLR)
library(glmnet)
library(dplyr)
library(tidyr)
library(readr)
library(mosaic)
library(MASS)
library(ggplot2)
appliances <- read_csv("energydata_complete.csv")
```


```{r}
#model_aov <- aov(Appliances ~ date + lights + T1 + RH_1 + T2 + RH_2 + T3 + RH_3 + T4 + RH_4 + T5 + RH_5 + T6 + RH_6 + T7 + RH_7 + T8 + RH_8 + T9 + RH_9 + T_out + Press_mm_hg + RH_out + Windspeed + Visibility + Tdewpoint + rv1 + rv2, Energy)
Energy3 <- appliances %>%
  select(-date)

model_aov <- aov(Appliances ~. , Energy3)
anova(model_aov)
```

Variables that have an impact:
lights, T1, RH_1, T2, RH_2, T3, T4, RH_4, T5, T6, RH_7, T8, RH_8, T9, T_out, Windspeed, Tdewpoint

##Full model with all variables
```{r}
appliances_data <- Energy3 #%>%
  #select(Appliances,lights, T1, RH_1, T2, RH_2, T3, T4, RH_4, T5, T6, RH_7, T8, RH_8, T9, T_out, Windspeed, Tdewpoint)
x = model.matrix(Appliances~., appliances_data)[,-1] # trim off the first column
# leaving only the predictors
y = appliances_data %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
```

```{r}
grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge_mod))
plot(ridge_mod) 
ridge_mod$lambda[50] #Display 50th lambda value
coef(ridge_mod)[,50] # Display coefficients associated with 50th lambda value
sqrt(sum(coef(ridge_mod)[-1,50]^2)) # Calculate l_2 norm
```

```{r}
ridge_mod$lambda[60] #Display 60th lambda value
coef(ridge_mod)[,60] # Display coefficients associated with 60th lambda value
sqrt(sum(coef(ridge_mod)[-1,60]^2)) # Calculate l2 norm

```

```{r}
predict(ridge_mod, s = 50, type = "coefficients")[1:28,]
```

```{r}
set.seed(1)
train = appliances_data %>%
sample_frac(0.5)
test = appliances_data %>%
setdiff(train)
x_train = model.matrix(Appliances~., train)[,-1]
x_test = model.matrix(Appliances~., test)[,-1]
y_train = train %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
y_test = test %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
ridge_mod = glmnet(x_train, y_train, alpha=0, lambda = grid, thresh = 1e-12)
ridge_pred = predict(ridge_mod, s = 4, newx = x_test)
mean((ridge_pred - y_test)^2)  #testMSE
```

```{r}
mean((mean(y_train) - y_test)^2)
ridge_pred = predict(ridge_mod, s = 1e10, newx = x_test)
mean((ridge_pred - y_test)^2)
```

```{r}
set.seed(1)
# Fit ridge regression model on training data
cv.out = cv.glmnet(x_train, y_train, alpha = 0)
# Select lamda that minimizes training MSE
bestlam = cv.out$lambda.min
bestlam
plot(cv.out) # Draw plot of training MSE as a function of lambda
# Use best lambda to predict test data
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
mean((ridge_pred - y_test)^2) # Calculate test MSE
```

```{r}
out = glmnet(x, y, alpha = 0) # Fit ridge regression model on full dataset
# Display coefficients using lambda chosen by CV
predict(out, type = "coefficients", s = bestlam)[1:28,]
```


##Limited Model with Select Variables

```{r}
appliances_data_limited <- Energy3 %>%
  select(Appliances,lights, T1, RH_1, T2, RH_2, T3, T4, RH_4, T5, T6, RH_7, T8, RH_8, T9, T_out, Windspeed, Tdewpoint)
x = model.matrix(Appliances~., appliances_data_limited)[,-1] # trim off the first column
# leaving only the predictors
y = appliances_data_limited %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
```

```{r}
grid = 10^seq(10, -2, length = 100)
ridge_mod = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge_mod))
plot(ridge_mod) 
ridge_mod$lambda[50] #Display 50th lambda value
coef(ridge_mod)[,50] # Display coefficients associated with 50th lambda value
sqrt(sum(coef(ridge_mod)[-1,50]^2)) # Calculate l_2 norm
```

```{r}
ridge_mod$lambda[60] #Display 60th lambda value
coef(ridge_mod)[,60] # Display coefficients associated with 60th lambda value
sqrt(sum(coef(ridge_mod)[-1,60]^2)) # Calculate l2 norm

```

```{r}
predict(ridge_mod, s = 50, type = "coefficients")[1:18,]
```

```{r}
set.seed(1)
train = appliances_data_limited %>%
sample_frac(0.5)
test = appliances_data_limited %>%
setdiff(train)
x_train = model.matrix(Appliances~., train)[,-1]
x_test = model.matrix(Appliances~., test)[,-1]
y_train = train %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
y_test = test %>%
select(Appliances) %>%
unlist() %>%
as.numeric()
ridge_mod = glmnet(x_train, y_train, alpha=0, lambda = grid, thresh = 1e-12)
ridge_pred = predict(ridge_mod, s = 4, newx = x_test)
mean((ridge_pred - y_test)^2)  #testMSE
```

```{r}
mean((mean(y_train) - y_test)^2)
ridge_pred = predict(ridge_mod, s = 1e10, newx = x_test)
mean((ridge_pred - y_test)^2)
```

```{r}
set.seed(1)
# Fit ridge regression model on training data
cv.out = cv.glmnet(x_train, y_train, alpha = 0)
# Select lamda that minimizes training MSE
bestlam = cv.out$lambda.min
bestlam
plot(cv.out) # Draw plot of training MSE as a function of lambda
# Use best lambda to predict test data
ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)
mean((ridge_pred - y_test)^2) # Calculate test MSE
```

```{r}
out = glmnet(x, y, alpha = 0) # Fit ridge regression model on full dataset
# Display coefficients using lambda chosen by CV
predict(out, type = "coefficients", s = bestlam)[1:18,]
```